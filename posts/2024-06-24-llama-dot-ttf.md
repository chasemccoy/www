Here's a thing I never would have imagined possible: [an LLM embedded into a font](https://fuglede.github.io/llama.ttf). 

Many applications (including Chrome and Firefox) use a font rendering engine called HarfBuzz, and HarfBuzz recently added support for running arbitrary WebAssemply code in order to "shape" the pixels that are drawn onscreen when rendering a font. 

You can see the font, llama.ttf, in action in [this video](https://www.youtube.com/watch?v=Q4bOyYctgFI&t=508s).

Over the past several decades we've seen computers be embedded into more and more contexts. Today, computers are everywhere, from our cars to the locks on our doors. [Computers have even been built and embedded into the digital worlds of video games](https://www.minecraft.net/en-us/article/deep-thought).

I wonder if, in the years to come, it might be LLMs that get embedded into _all the things_.

A smart refrigerator that can reason about what's inside and maintain a grocery list for you? A font that completes your sentences? A doorbell that answers in your voice and tone when you're not at home? In-flight entertainment that generate content based on your preferences?

Strange times ahead.